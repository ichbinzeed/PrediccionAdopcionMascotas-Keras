# ğŸ¾ PredicciÃ³n de AdopciÃ³n de Mascotas con Redes Neuronales (Keras)

## ğŸ¯ Resumen del Proyecto

Este proyecto demuestra la aplicaciÃ³n de tÃ©cnicas de **Deep Learning** para construir un modelo predictivo que determina la probabilidad de adopciÃ³n de una mascota. Utilizando el dataset `petfinder-mini.csv`, se desarrollÃ³ una **red neuronal con Keras (TensorFlow)** ğŸ§  para clasificar si una mascota serÃ¡ adoptada o no, basÃ¡ndose en sus caracterÃ­sticas.

El objetivo fue transformar un problema de predicciÃ³n de velocidad de adopciÃ³n (mÃºltiples categorÃ­as) en una tarea de **clasificaciÃ³n binaria** (adoptado âœ… vs. no adoptado âŒ), donde `AdoptionSpeed == 4` (no adoptado) se mapea a la clase `0` y el resto (adoptado) a la clase `1`.

## ğŸ› ï¸ MetodologÃ­a Aplicada

El flujo de trabajo implementado cubre las etapas esenciales de un proyecto de Machine Learning:

1.  **ğŸ“Š PreparaciÃ³n de Datos:**
    *   Carga y limpieza inicial del dataset utilizando **Pandas**.
    *   TransformaciÃ³n de la variable objetivo a un formato binario.

2.  **âœ¨ IngenierÃ­a y Preprocesamiento de CaracterÃ­sticas:**
    *   IdentificaciÃ³n y separaciÃ³n de caracterÃ­sticas numÃ©ricas y categÃ³ricas.
    *   **NormalizaciÃ³n** de variables numÃ©ricas.
    *   **CodificaciÃ³n One-Hot** para variables categÃ³ricas.
    *   Todo el preprocesamiento se realizÃ³ eficientemente utilizando **capas de preprocesamiento de Keras** (`Normalization`, `StringLookup`, `IntegerLookup`, `CategoryEncoding`), resultando en un conjunto final de 216 caracterÃ­sticas de entrada para el modelo.

3.  **ğŸ§  Desarrollo del Modelo de Deep Learning:**
    *   DiseÃ±o y construcciÃ³n de una **red neuronal secuencial** en Keras.
    *   Arquitectura con mÃºltiples capas densas (Dense) y funciones de activaciÃ³n ReLU.
    *   ImplementaciÃ³n de tÃ©cnicas de regularizaciÃ³n para combatir el sobreajuste: **RegularizaciÃ³n L2, Batch Normalization y Dropout**.
    *   Capa de salida con activaciÃ³n **sigmoide**, adecuada para clasificaciÃ³n binaria.

4.  **âš™ï¸ Entrenamiento y OptimizaciÃ³n:**
    *   CompilaciÃ³n del modelo utilizando el optimizador **Adam** y la funciÃ³n de pÃ©rdida `binary_crossentropy`.
    *   Entrenamiento del modelo monitoreando la mÃ©trica de `accuracy`.
    *   Uso de `EarlyStopping` para detener el entrenamiento de forma Ã³ptima y evitar el sobreajuste, restaurando los mejores pesos obtenidos durante la validaciÃ³n.

5.  **ğŸ“ˆ EvaluaciÃ³n del Rendimiento:**
    *   AnÃ¡lisis de las curvas de aprendizaje (pÃ©rdida en entrenamiento vs. validaciÃ³n).
    *   CÃ¡lculo y visualizaciÃ³n de la **matriz de confusiÃ³n** para evaluar el desempeÃ±o en el conjunto de prueba.
    *   Reporte de la precisiÃ³n (accuracy) final.

## ğŸ’» TecnologÃ­as Clave Utilizadas

*   **Lenguaje:** Python 3 ğŸ
*   **Deep Learning:** TensorFlow & Keras ğŸ”¥
*   **ManipulaciÃ³n de Datos:** Pandas ğŸ¼, NumPy
*   **Machine Learning (utilidades):** Scikit-learn sklearn
*   **VisualizaciÃ³n:** Matplotlib ğŸ“Š, Seaborn ğŸ“‰
*   **Entorno de Desarrollo:** Jupyter Notebook ğŸ““

## ğŸ† Resultados Destacados

*   El modelo de red neuronal alcanzÃ³ una **precisiÃ³n (accuracy) del 73.18%** en el conjunto de datos de prueba.
*   La precisiÃ³n en el conjunto de entrenamiento fue del **73.33%**, indicando un buen equilibrio y evitando un sobreajuste significativo gracias a las tÃ©cnicas de regularizaciÃ³n implementadas.
*   La matriz de confusiÃ³n y las curvas de pÃ©rdida (disponibles en el notebook) ofrecen una visiÃ³n detallada del comportamiento y la capacidad de generalizaciÃ³n del modelo.

## ğŸ’¡ ConclusiÃ³n

Este proyecto demuestra la capacidad de construir modelos de Deep Learning robustos para problemas de clasificaciÃ³n con datos tabulares, gestionando el preprocesamiento de caracterÃ­sticas directamente dentro del pipeline de Keras y aplicando estrategias efectivas para el entrenamiento y la evaluaciÃ³n.

---
